{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Mining Model Structured Data (Part 2)",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up2MQL0imvLy"
      },
      "source": [
        "*Hands-on of Big Data Analyst with TuV Certified Qualification*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y64-VX3WSZ8"
      },
      "source": [
        "# 2. Data Mining Model - Structured Data (Part 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLW2pOyWptqh"
      },
      "source": [
        "Sub topics covered in this practice:\n",
        "* Classification\n",
        "* Clustering\n",
        "* Association"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHQnzWRtigPN"
      },
      "source": [
        "### **Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG8z8oVNULmV"
      },
      "source": [
        "Here we model the classification model from telco customer churn data (https://www.kaggle.com/blastchar/telco-customer-churn). This data is consist of customer profile, customer subscription history, and their churn information.\n",
        "\n",
        "Each row represents a customer, each column contains customer’s attributes described below:\n",
        "1.   customerID : Customer ID\n",
        "2.   gender : Whether the customer is a male or a female\n",
        "3.   SeniorCitizen : Whether the customer is a senior citizen or not (1, 0)\n",
        "4.   Partner : Whether the customer has a partner or not (Yes, No)\n",
        "5.   Dependents : Whether the customer has dependents or not (Yes, No)\n",
        "6.   tenure : Number of months the customer has stayed with the company\n",
        "7.   PhoneService : Whether the customer has a phone service or not (Yes, No)\n",
        "8.   MultipleLines : Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
        "9.   InternetService : Customer’s internet service provider (DSL, Fiber optic, No)\n",
        "10.   OnlineSecurity: Whether the customer has online security or not (Yes, No, No internet service)\n",
        "11.   OnlineBackup: Whether the customer has online backup or not (Yes, No, No internet service)\n",
        "12.   DeviceProtection: Whether the customer has device protection or not (Yes, No, No internet service)\n",
        "13.   TechSupport : Whether the customer has tech support or not (Yes, No, No internet service)\n",
        "14.   StreamingTV : Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
        "15.   StreamingMovies : Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
        "16.   Contract : The contract term of the customer (Month-to-month, One year, Two year)\n",
        "17.   PaperlessBilling : Whether the customer has paperless billing or not (Yes, No)\n",
        "18.   PaymentMethod : The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
        "19.   MonthlyCharges : The amount charged to the customer monthly\n",
        "20.   TotalCharges : The total amount charged to the customer\n",
        "21.   Churn Whether: the customer churned or not (Yes or No)\n",
        "\n",
        "We will predict customer behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgluYCulxxIJ"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LnjbBxXx0vz"
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ6Q4IRnmbRG"
      },
      "source": [
        "Import Raw Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa0blw2s6G7X"
      },
      "source": [
        "# Import Data to Google Colab\n",
        "df_churn = pd.read_csv('https://raw.githubusercontent.com/dianrdn/data/master/customer_churn.csv', sep = ';')\n",
        "df_churn\n",
        "\n",
        "# Show 10 first Row\n",
        "df_churn.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGOqBrwfxGsG"
      },
      "source": [
        "# Prints the Dataset Information\n",
        "df_churn.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw1TLO4wmqi0"
      },
      "source": [
        "# Prints Descriptive Statistics\n",
        "df_churn.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovdislrOmxw7"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f99fF2tm3r9"
      },
      "source": [
        "Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqMBNZiKm-KV"
      },
      "source": [
        "# Check for Missing Values\n",
        "df_churn.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvHrvTq5nBKG"
      },
      "source": [
        "# Search for Median Value\n",
        "median = df_churn['TotalCharges'].median()\n",
        "\n",
        "# Use Median to Replace Missing Values\n",
        "df_churn['TotalCharges'].fillna(median, inplace=True)\n",
        "\n",
        "# Check for Missing Values\n",
        "df_churn.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu3-_cMqolmD"
      },
      "source": [
        "Encode Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4QClyfiopNW"
      },
      "source": [
        "# Import Module\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Encoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Encode Categorical Data\n",
        "df_encoded = pd.DataFrame(encoder.fit_transform(df_churn[['gender', 'InternetService', 'Contract', 'PaymentMethod']]))\n",
        "df_encoded.columns = encoder.get_feature_names(['gender', 'InternetService', 'Contract', 'PaymentMethod'])\n",
        "\n",
        "# Replace Categotical Data with Encoded Data\n",
        "df_churn.drop(['gender', 'InternetService', 'Contract', 'PaymentMethod'] ,axis=1, inplace=True)\n",
        "df_encoded= pd.concat([df_churn, df_encoded], axis=1)\n",
        "\n",
        "# Show Encoded Dataframe\n",
        "df_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtGKwoaCpeAs"
      },
      "source": [
        "Set Feature and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awfUHmfrph6W"
      },
      "source": [
        "# Select Features\n",
        "feature = df_encoded.drop(['customerID', 'TotalCharges', 'Churn'], axis=1)\n",
        "feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu1COTYDqVoC"
      },
      "source": [
        "# Select Target\n",
        "target = df_encoded['Churn']\n",
        "target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKGonYC7qhGA"
      },
      "source": [
        "Set Training and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td_W4NOBqpCI"
      },
      "source": [
        "# Set Training and Testing Data (70:30)\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "X_train, X_test, y_train, y_test  = train_test_split(feature , target, shuffle = True, test_size=0.3, random_state=1)\n",
        "\n",
        "# Show the Training and Testing Data\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW3ulO_V--JF"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBpuFXsXxoOW"
      },
      "source": [
        "#### ***Decision Tree***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB0NTjxCZ3hw"
      },
      "source": [
        "A decision tree is a flowchart-like tree structure where an internal node represents feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value. It partitions the tree in recursively manner call recursive partitioning. This flowchart-like structure helps you in decision making."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5EO9O_z2qKC"
      },
      "source": [
        "Modeling Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_97Grv1xHky"
      },
      "source": [
        "# Import Module\n",
        "from sklearn import tree\n",
        "\n",
        "# Modeling Decision Tree\n",
        "dtc = tree.DecisionTreeClassifier(min_impurity_decrease=0.01)\n",
        "dtc.fit(X_train, y_train)\n",
        "\n",
        "# Predict to Test Data \n",
        "y_pred_dtc = dtc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t715tIDhsQlp"
      },
      "source": [
        "# Visualize Tree\n",
        "\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(dtc, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,\n",
        "                class_names=['notchurn', 'churn'],\n",
        "                feature_names=['SeniorCitizen',\t'Partner',\t'Dependents', 'tenure',\t'PhoneService', 'OnlineSecurity',\t'OnlineBackup',\t'DeviceProtection',\n",
        "                               'TechSupport',\t'StreamingTV',\t'StreamingMovies',\t'PaperlessBilling',\t'MonthlyCharges', 'gender_Female',\n",
        "                               'gender_Male',\t'InternetService_DSL', 'InternetService_Fiber optic', 'InternetService_No',\t'Contract_Month-to-month',\n",
        "                               'Contract_One year',\t'Contract_Two year',\t'PaymentMethod_Bank transfer (automatic)', 'PaymentMethod_Credit card (automatic)',\n",
        "                               'PaymentMethod_Electronic check',\t'PaymentMethod_Mailed check'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hQJbLAV2uGm"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYNobAynxOYC"
      },
      "source": [
        "# Import Module\n",
        "from sklearn import metrics\n",
        "\n",
        "# Show the Confussion Matrix\n",
        "cm_dtc = metrics.confusion_matrix(y_test, y_pred_dtc)\n",
        "cm_dtc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzC3woEkaFhz"
      },
      "source": [
        "# Show the Accuracy, Precision, Recall\n",
        "acc_dtc = metrics.accuracy_score(y_test, y_pred_dtc)\n",
        "prec_dtc = metrics.precision_score(y_test, y_pred_dtc)\n",
        "rec_dtc = metrics.recall_score(y_test, y_pred_dtc)\n",
        "f1_dtc = metrics.f1_score(y_test, y_pred_dtc)\n",
        "kappa_dtc = metrics.cohen_kappa_score(y_test, y_pred_dtc)\n",
        "\n",
        "print(\"Accuracy:\", acc_dtc)\n",
        "print(\"Precision:\", prec_dtc)\n",
        "print(\"Recall:\", rec_dtc)\n",
        "print(\"F1 Score:\", f1_dtc)\n",
        "print(\"Cohens Kappa Score:\", kappa_dtc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhkuuaY4d2Wb"
      },
      "source": [
        "# Import Visualization Package\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set Size and Style\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Visualize ROC Curve\n",
        "y_pred_dtc_proba = dtc.predict_proba(X_test)[::,1]\n",
        "fprdtc, tprdtc, _ = metrics.roc_curve(y_test,  y_pred_dtc_proba)\n",
        "aucdtc = metrics.roc_auc_score(y_test, y_pred_dtc_proba)\n",
        "plt.plot(fprdtc,tprdtc,label=\"Decision Tree, auc=\"+str(aucdtc))\n",
        "plt.title('ROC Curve - Decision Tree')\n",
        "plt.xlabel('false positive rate') \n",
        "plt.ylabel('true positive rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOtGq06Yx5m-"
      },
      "source": [
        "#### ***Naive Bayes***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSjixvtW3BCT"
      },
      "source": [
        "Modeling Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhyV9oiBxYaR"
      },
      "source": [
        "# Import Module\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "\n",
        "# Modeling Naive Bayes Classifier\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Predict to Test Data\n",
        "y_pred_gnb= gnb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIj46eRf2-X2"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5hK9_mKxaGy"
      },
      "source": [
        "# Show the Confussion Matrix\n",
        "cm_gnb = metrics.confusion_matrix(y_test, y_pred_gnb)\n",
        "cm_gnb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUBWww1Wxb8E"
      },
      "source": [
        "# Show the Accuracy, Precision, Recall\n",
        "acc_gnb = metrics.accuracy_score(y_test, y_pred_gnb)\n",
        "prec_gnb = metrics.precision_score(y_test, y_pred_gnb)\n",
        "rec_gnb = metrics.recall_score(y_test, y_pred_gnb)\n",
        "f1_gnb = metrics.f1_score(y_test, y_pred_gnb)\n",
        "kappa_gnb = metrics.cohen_kappa_score(y_test, y_pred_gnb)\n",
        "\n",
        "print(\"Accuracy:\", acc_gnb)\n",
        "print(\"Precision:\", prec_gnb)\n",
        "print(\"Recall:\", rec_gnb)\n",
        "print(\"F1 Score:\", f1_gnb)\n",
        "print(\"Cohens Kappa Score:\", kappa_gnb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvjEOHVoeaKY"
      },
      "source": [
        "# ROC Curve\n",
        "y_pred_gnb_proba = gnb.predict_proba(X_test)[::,1]\n",
        "fprgnb, tprgnb, _ = metrics.roc_curve(y_test,  y_pred_gnb_proba)\n",
        "aucgnb = metrics.roc_auc_score(y_test, y_pred_gnb_proba)\n",
        "plt.plot(fprgnb,tprgnb,label=\"Naive Bayes, auc=\"+str(aucgnb))\n",
        "plt.title('ROC Curve - Naive Bayes')\n",
        "plt.xlabel('false positive rate') \n",
        "plt.ylabel('true positive rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smDzk-Kox9Hg"
      },
      "source": [
        "#### ***Model Comparison***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mbup_VsxfE3"
      },
      "source": [
        "# Comparing Model Performance\n",
        "print(\"Decision Tree Accuracy =\",acc_dtc)\n",
        "print(\"Decision Tree Precision =\",prec_dtc)\n",
        "print(\"Decision Tree Recall =\",rec_dtc)\n",
        "print(\"Decision Tree F1-Score =\", f1_dtc)\n",
        "print(\"_______________________\")\n",
        "print(\"Naive Bayes Accuracy =\", acc_gnb)\n",
        "print(\"Naive Bayes Precision =\", prec_gnb)\n",
        "print(\"Naive Bayes Recall =\", rec_gnb)\n",
        "print(\"Naive Bayes F1-Score =\", f1_gnb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3vmPWKqagI6"
      },
      "source": [
        "# Comparing ROC Curve\n",
        "plt.plot(fprdtc,tprdtc,label=\"Decision Tree, auc=\"+str(aucdtc))\n",
        "plt.plot(fprgnb,tprgnb,label=\"Naive Bayes, auc=\"+str(aucgnb))\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjoQHUox-TnG"
      },
      "source": [
        "# Create Datafame Contains Fature and Result of prediction\n",
        "df_compare = X_test.copy()\n",
        "df_compare['ActualClass'] = y_test\n",
        "df_compare['DecisonTree'] = y_pred_dtc\n",
        "df_compare['NaiveBayes'] = y_pred_gnb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nklO5GGt_t75"
      },
      "source": [
        "df_compare.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpkwePVE32I1"
      },
      "source": [
        "#### **Predict New Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "837DnWva38Wb"
      },
      "source": [
        "Import New Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJJASQ204a8f"
      },
      "source": [
        "# Import New Dataset\n",
        "df_new_churn = pd.read_csv('https://raw.githubusercontent.com/dianrdn/data/master/churn_new.csv', sep =';')\n",
        "df_new_churn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hku-u7Tv4akn"
      },
      "source": [
        "Preprocess the New Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzVa2na64iIy"
      },
      "source": [
        "# Import Module\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Encoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Encode Categorical Data\n",
        "df_new_churn2 = pd.DataFrame(encoder.fit_transform(df_new_churn[['gender', 'InternetService', 'Contract', 'PaymentMethod']]))\n",
        "df_new_churn2.columns = encoder.get_feature_names(['gender', 'InternetService', 'Contract', 'PaymentMethod'])\n",
        "\n",
        "# Concat the Encoded Data\n",
        "df_new_churn_encoded = df_new_churn.drop(['gender', 'InternetService', 'Contract', 'PaymentMethod'] ,axis=1, inplace=True)\n",
        "df_new_churn_encoded = pd.concat([df_new_churn, df_new_churn2], axis=1)\n",
        "\n",
        "# Show Encoded Dataframe\n",
        "df_new_churn_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TQZhkrv4pCN"
      },
      "source": [
        "# Select Features\n",
        "new_feature = df_new_churn_encoded.drop(['customerID', 'TotalCharges'], axis=1)\n",
        "new_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiWunBft5SIW"
      },
      "source": [
        "Predict New Customer Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_sy82eM4120"
      },
      "source": [
        "# Predict using Decision Tree Classifier\n",
        "new_predicted_dtree = pd.DataFrame(dtc.predict(new_feature), columns = ['churn_decision_tree'])\n",
        "new_predicted_dtree.reset_index()\n",
        "new_predicted_dtree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opd8sQhc5Afx"
      },
      "source": [
        "# Predict using Naive Bayes Classifier\n",
        "new_predicted_nb = pd.DataFrame(gnb.predict(new_feature), columns = ['churn_naive_bayes'])\n",
        "new_predicted_nb.reset_index()\n",
        "new_predicted_nb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnnZnS1e5TBg"
      },
      "source": [
        "Show Prediction Comparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF994Tlz5In3"
      },
      "source": [
        "# Show Prediction Result\n",
        "pred_new_churn = pd.concat([df_new_churn, new_predicted_dtree, new_predicted_nb], axis=1)\n",
        "pred_new_churn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih_dVB9G5Vtj"
      },
      "source": [
        "Save Prediction Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZQKhcL35Y5J"
      },
      "source": [
        "# Save Prediction Result\n",
        "pred_new_churn.to_csv('new_churn_prediction.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkGom3b6iiy0"
      },
      "source": [
        "### **Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--o2UrYRyKxa"
      },
      "source": [
        "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdDREVjJyQ20"
      },
      "source": [
        "Here we model the clustering from customer income and spend data. We use this model to perform customer segmentation. We differentiate customers into the optimum number of groups based on their shared income and spend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Leqbe4bNx-jp"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG_86GjfyA4e"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IktWtCoJybaJ"
      },
      "source": [
        "Import Raw Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onw9MVUJphxP"
      },
      "source": [
        "# Import Dataset\n",
        "df_income = pd.read_csv('https://raw.githubusercontent.com/rc-dbe/bigdatacertification/master/dataset/clustering.csv')\n",
        "df_income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7HLHYGDya76"
      },
      "source": [
        "# Prints the Dataset Information\n",
        "df_income.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTvahGyOydvJ"
      },
      "source": [
        "# Prints Descriptive Statistics\n",
        "df_income.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4gO6Bs6yoMX"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuwe0UT8yqH-"
      },
      "source": [
        "First, we standardize the data to equalize the range and/or data variability. Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqo2LuvKymlg"
      },
      "source": [
        "# Importing Standardscalar Module \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "# Set Name for StandardScaler as scaler\n",
        "scaler = StandardScaler() \n",
        "\n",
        "# Fit Standardization\n",
        "column_names = df_income.columns.tolist()\n",
        "df_income[column_names] = scaler.fit_transform(df_income[column_names])\n",
        "df_income.sort_index(inplace=True)\n",
        "df_income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrZ_HvD5zB-C"
      },
      "source": [
        "Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yizZskvoy-mv"
      },
      "source": [
        "# Styling Plot\n",
        "sns.set() \n",
        "plt.rcParams['figure.figsize'] = (16, 9)\n",
        "\n",
        "# Visualizing the Data\n",
        "sns.scatterplot(x='INCOME', y='SPEND', data=df_income)\n",
        "plt.title('Customer Segments')\n",
        "plt.xlabel('Annual Income')\n",
        "plt.ylabel('Annual Spend')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fqVvUukzTE7"
      },
      "source": [
        "#### ***K-Means Clustering***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk_vDIH6zXlW"
      },
      "source": [
        "Kmeans algorithm is an iterative algorithm that tries to partition the dataset into Kpre-defined distinct non-overlapping subgroups (clusters) where each data point belongs to only one group. It tries to make the inter-cluster data points as similar as possible while also keeping the clusters as different (far) as possible. It assigns data points to a cluster such that the sum of the squared distance between the data points and the cluster’s centroid (arithmetic mean of all the data points that belong to that cluster) is at the minimum. The less variation we have within clusters, the more homogeneous (similar) the data points are within the same cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csuPTvO5zb58"
      },
      "source": [
        "Search for the Optimum Number of Clusters (k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61IHqkSipzfT"
      },
      "source": [
        "# Transform Data Frame to Numpy Array\n",
        "income = df_income.to_numpy()\n",
        "income\n",
        "\n",
        "# Elbow Method\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(1,11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(income)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "  \n",
        "# Visualize \n",
        "plt.plot(range(1,11),wcss)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('wcss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysAJ82tKp1SX"
      },
      "source": [
        "# Silhoutte Method\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "for n_cluster in range(2, 11):\n",
        "    kmeans = KMeans(n_clusters=n_cluster).fit(income)\n",
        "    label = kmeans.labels_\n",
        "    sil_coeff = silhouette_score(income, label, metric='euclidean')\n",
        "    print('For n_clusters={}, The Silhouette Coefficient is {}'.format(n_cluster, sil_coeff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a48acsIU1NeI"
      },
      "source": [
        "Modeling K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eKJqds7p3Vq"
      },
      "source": [
        "# Apply the K-Means Model to the Data\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "cluster = kmeans.fit_predict(income)\n",
        "\n",
        "# Visualising Clusters for k=3\n",
        "sns.scatterplot(x='INCOME', y='SPEND', data=df_income)\n",
        "plt.scatter(income[cluster == 0, 0], income[cluster == 0, 1], s = 50, label = 'Cluster 1')\n",
        "plt.scatter(income[cluster == 1, 0], income[cluster == 1, 1], s = 50, label = 'Cluster 2')\n",
        "plt.scatter(income[cluster == 2, 0], income[cluster == 2, 1], s = 50, label = 'Cluster 3')\n",
        "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],s=200,marker='s', alpha=0.7, label='Centroids')\n",
        "plt.title('Customer segments')\n",
        "plt.xlabel('Annual income')\n",
        "plt.ylabel('Annual spend')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FTwlfAp6ZBf"
      },
      "source": [
        "# Add Cluster Information to the Raw Data\n",
        "df_income['cluster'] = cluster\n",
        "df_income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQXnX8UV6g5F"
      },
      "source": [
        "# Save= Result\n",
        "df_income.to_csv('income_clusters.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZMMP5QIp7kF"
      },
      "source": [
        "#### ***Hierarchical Clustering***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QnoAhvr1m2a"
      },
      "source": [
        "Hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis which seeks to build a hierarchy of clusters. The endpoint is a set of clusters, where each cluster is distinct from each other cluster, and the objects within each cluster are broadly similar to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I12Urjo8p_eZ"
      },
      "source": [
        "# Modeling and Visualizing Clusters by Dendogram\n",
        "import scipy.cluster.hierarchy as sch\n",
        "dend = sch.dendrogram(sch.linkage(income, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Customer')\n",
        "plt.ylabel('Euclidean')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDGayf3V1wKa"
      },
      "source": [
        "# Apply the Hierarchical Clustering Model to the Dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
        "hcluster = hc.fit_predict(income)\n",
        "\n",
        "# Visualising Clusters for k=3\n",
        "sns.scatterplot(x='INCOME', y='SPEND', data=df_income)\n",
        "plt.scatter(income[hcluster == 0, 0], income[hcluster == 0, 1], s = 50, label = 'Cluster 1')\n",
        "plt.scatter(income[hcluster == 1, 0], income[hcluster == 1, 1], s = 50, label = 'Cluster 2')\n",
        "plt.scatter(income[hcluster == 2, 0], income[hcluster == 2, 1], s = 50, label = 'Cluster 3')\n",
        "plt.title('Clusters of customers')\n",
        "plt.xlabel('Annual Income')\n",
        "plt.ylabel('Annual Spend')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQjZvElYirsW"
      },
      "source": [
        "### **Association**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As4V5rSyqFCW"
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y6pF719qGqa"
      },
      "source": [
        "# Import dataset\n",
        "retail_df = pd.read_excel(\"https://github.com/rc-dbe/bigdatacertification/blob/master/dataset/Online%20Retail.xlsx?raw=true\")\n",
        "retail_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdgt9bqpqIEP"
      },
      "source": [
        "# Remove additional spaces\n",
        "retail_df['Description'] = retail_df['Description'].str.strip()\n",
        "\n",
        "# Remove NA values\n",
        "retail_df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)\n",
        "\n",
        "# Remove cancelled orders\n",
        "retail_df['InvoiceNo'] = retail_df['InvoiceNo'].astype('str')\n",
        "retail_df = retail_df[~retail_df['InvoiceNo'].str.contains('C')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0954EQaqKI0"
      },
      "source": [
        "# Create Encode Function\n",
        "def encode_units(x):\n",
        "    if x <= 0:\n",
        "        return 0\n",
        "    if x >= 1:\n",
        "        return 1\n",
        "\n",
        "def create_basket(country_filter):\n",
        "    basket = (retail_df[retail_df['Country'] == country_filter]\n",
        "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
        "          .sum().unstack().reset_index().fillna(0)\n",
        "          .set_index('InvoiceNo'))\n",
        "    return basket"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzBQtyH8qLns"
      },
      "source": [
        "country_filter = \"France\"\n",
        "basket_french = create_basket(\"France\")\n",
        "basket_sets = basket_french.applymap(encode_units)\n",
        "basket_sets.drop('POSTAGE', inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF4trvtzqNAy"
      },
      "source": [
        "frequent_itemsets = apriori(basket_sets, min_support=0.05, use_colnames=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzK7rZODcsPP"
      },
      "source": [
        "Illustration of association rules, source: [A Gentle Introduction on Market Basket Analysis](https://towardsdatascience.com/a-gentle-introduction-on-market-basket-analysis-association-rules-fa4b986a40ce)\n",
        "![Example](https://github.com/rc-dbe/bigdatacertification/blob/master/images/1_--iUPe_DtzKdongjqZ2lOg.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfkZqCz2qOXV"
      },
      "source": [
        "# Generate Rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
        "rules.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4tnn8HrdXe_"
      },
      "source": [
        "# Sorting\n",
        "rules.sort_values([\"confidence\"], axis=0, \n",
        "                 ascending=False, inplace=True) \n",
        "rules"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}